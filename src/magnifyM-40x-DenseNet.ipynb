{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Model\n",
    "\n",
    "this file will use folder \"dataset_used\" that generate from \"BreakHisModel-1.ipynb\"\n",
    "and this will be used transfer learning / pre trained model RestNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking their lengths\n",
    "# train \n",
    "len_train_benign = len(os.listdir(\"../data_magnify/40x/Cancer_train/benign/\"))\n",
    "len_train_malignant = len(os.listdir(\"../data_magnify/40x/Cancer_train/malignant/\"))\n",
    "# test \n",
    "len_test_benign = len(os.listdir(\"../data_magnify/40x/Cancer_test/benign/\"))\n",
    "len_test_malignant = len(os.listdir(\"../data_magnify/40x/Cancer_test/malignant/\"))\n",
    "# val \n",
    "len_validation_benign = len(os.listdir(\"../data_magnify/40x/Cancer_validation/benign/\"))\n",
    "len_validation_malignant = len(os.listdir(\"../data_magnify/40x/Cancer_validation/malignant/\"))\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(\" \")\n",
    "print(\"Benign   :\", len_train_benign)\n",
    "print(\"Malignant:\", len_train_malignant)\n",
    "print(\" \")\n",
    "print(\"Validation Data\")\n",
    "print(\" \")\n",
    "print(\"Benign size    :\",len_validation_benign)\n",
    "print(\"Malignant size :\",len_validation_malignant)\n",
    "print(\" \")\n",
    "print(\"Testing Data:\")\n",
    "print(\" \")\n",
    "print(\"Benign size    :\",len_test_benign)\n",
    "print(\"Malignant size :\",len_test_malignant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Generator\n",
    "- Reference: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "- Generates batches of tensor image data with real-time data augmentation.\n",
    "- Thus CNN sees new set of images with different variation at each epoch.\n",
    "- One of the useful methods to prevent the model from Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Image Data Generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the images for image data generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "  \"../data_magnify/40x/Cancer_train/\",\n",
    "  target_size=(128, 128),\n",
    "  class_mode=\"categorical\",\n",
    "  batch_size = 32,\n",
    "  )\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "  \"../data_magnify/40x/Cancer_validation/\", \n",
    "  target_size=(128, 128), \n",
    "  class_mode=\"categorical\",\n",
    "  batch_size=32, \n",
    "  )\n",
    "\n",
    "  # Loading the test data using Image Data Generator\n",
    "test_generator = datagen.flow_from_directory(\n",
    "  \"../data_magnify/40x/Cancer_test/\", \n",
    "  target_size=(128,128), \n",
    "  class_mode=\"categorical\", \n",
    "  batch_size=32, \n",
    "  shuffle=False\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Layer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the base model -> Fine Tune\n",
    "DenseNet121_layer = DenseNet121(\n",
    "  include_top=False,\n",
    "  input_shape=(128, 128, 3)\n",
    ")\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(DenseNet121_layer.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 50\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in DenseNet121_layer.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet121_layer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR optimizer\n",
    "- tf.keras.optimizers.schedules.InverseTimeDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = int(len_train_benign) * 2\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the learning rate to reduce gradually over the training period\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  initial_learning_rate=0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*5,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "def get_optimizer():\n",
    "  return tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = np.linspace(0,100000)\n",
    "lr = lr_schedule(step)\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(step/STEPS_PER_EPOCH, lr)\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "_ = plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning\n",
    "- epoch[0, 0,2, 0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.0, 0.2, 0.4]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning_denseNet').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_DROPOUT],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    # RestNet Layer\n",
    "    DenseNet121_layer,\n",
    "    \n",
    "    # Flattening the layers\n",
    "    Flatten(),\n",
    "\n",
    "    # Adding the dense layer\n",
    "    Dropout(hparams[HP_DROPOUT]),\n",
    "    Dense(256, activation='relu'),\n",
    "    \n",
    "    Dropout(hparams[HP_DROPOUT]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax'),\n",
    "  ])\n",
    "  model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer = get_optimizer(), \n",
    "    metrics = ['accuracy']\n",
    "  )\n",
    "\n",
    "  model.fit(\n",
    "    train_generator, \n",
    "    validation_data=val_generator, \n",
    "    epochs=15,\n",
    "    callbacks=[early_stop],\n",
    "    verbose = 1\n",
    "  ) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(test_generator)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_HP = time.time()\n",
    "\n",
    "session_num = 0\n",
    "for dropout_rate in HP_DROPOUT.domain.values:\n",
    "  hparams = {\n",
    "    HP_DROPOUT: dropout_rate,\n",
    "  }\n",
    "  run_name = \"run-%d\" % session_num\n",
    "  print('--- Starting trial: %s' % run_name)\n",
    "  print({h.name: hparams[h] for h in hparams})\n",
    "  run('logs/hparam_tuning/' + run_name, hparams)\n",
    "  session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_HP = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_time_second= end_time_HP - start_time_HP\n",
    "convert_minute = (Total_time_second) // 60\n",
    "modulo_second = (Total_time_second) % 60\n",
    "print(\"total time run HyperParameter Tune : {} Minutes, {} Seconds\".format(convert_minute, modulo_second) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning_denseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model CNN Pretrained model\n",
    "- with DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_model = Sequential([\n",
    "  # RestNet Layer\n",
    "  DenseNet121_layer,\n",
    "  \n",
    "  # Flattening the layers\n",
    "  Flatten(),\n",
    "  Dropout(0.4),\n",
    "\n",
    "  # Adding the dense layer\n",
    "  Dense(256, activation='relu'),\n",
    "  Dropout(0.4),\n",
    "  \n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(2, activation='softmax'),\n",
    "])\n",
    "\n",
    "# cancer_model.layers[0].trainable = False\n",
    "cancer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "cancer_model.compile(\n",
    "  loss='categorical_crossentropy', \n",
    "  optimizer = get_optimizer(), \n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is fitted using train and validation generator for 200 epochs\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = cancer_model.fit(\n",
    "  train_generator, \n",
    "  validation_data=val_generator, \n",
    "  epochs=200 ,\n",
    "  callbacks=[early_stop],\n",
    "  verbose = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(\"The time of execution of above program is :\",(end_time-start_time) * 10**3, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_time_second= end_time-start_time\n",
    "convert_minute = (Total_time_second) // 60\n",
    "modulo_second = (Total_time_second) % 60\n",
    "print(\"total time run : {} Minutes, {} Seconds\".format(convert_minute, modulo_second) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the model results\n",
    "\n",
    "# Getting the accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Getting the losses\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# No of epochs it trained\n",
    "epochs_range = history.epoch\n",
    "\n",
    "# Plotting Training and Validation accuracy\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#Plotting Training and Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cancer_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../src/output/denseNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_model.save(filepath=\"../src/output/denseNet/denseNet_HP.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27f99e149f39fc2698301b252ecdbf2df6001c346d183b880337b0c4a23ac95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
